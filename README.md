# An√°lise de Dados com Apache Spark

Este projeto utiliza o Apache Spark para realizar an√°lises de dados e treinamento de modelos de machine learning. O c√≥digo √© escrito em Python com a API `pyspark` e inclui etapas como limpeza de dados, transforma√ß√£o, treinamento de modelos e avalia√ß√£o de desempenho.

## üöÄ Sobre o Projeto

O objetivo deste projeto √© demonstrar como o Apache Spark pode ser usado para processar grandes volumes de dados e construir modelos de machine learning escal√°veis. O c√≥digo realiza as seguintes etapas:

1. **Carregamento de dados**: Leitura de um arquivo CSV.
2. **Limpeza e transforma√ß√£o**: Remo√ß√£o de valores nulos e convers√£o de vari√°veis categ√≥ricas em num√©ricas.
3. **Engenharia de features**: Cria√ß√£o de um vetor de features para treinamento do modelo.
4. **Treinamento do modelo**: Uso de regress√£o log√≠stica para classifica√ß√£o.
5. **Avalia√ß√£o do modelo**: C√°lculo da acur√°cia do modelo.
6. **Implanta√ß√£o do modelo**: Salvamento e carregamento do modelo treinado.

## üìã Requisitos

Para executar este projeto, voc√™ precisar√° de:

- **Apache Spark**: Instalado e configurado.
- **Python 3.x**: Com as seguintes bibliotecas instaladas:
  ```bash
  pip install pyspark pandas numpy
